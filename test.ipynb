{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-04-24T02:00:53.631124Z",
     "iopub.status.busy": "2024-04-24T02:00:53.630786Z",
     "iopub.status.idle": "2024-04-24T02:00:55.689613Z",
     "shell.execute_reply": "2024-04-24T02:00:55.688661Z",
     "shell.execute_reply.started": "2024-04-24T02:00:53.631056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T10:30:21.260575500Z",
     "start_time": "2024-05-17T10:30:14.929016400Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib.metadata\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "\n",
    "from keras.src.layers import Bidirectional, LSTM\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:00:55.693553Z",
     "iopub.status.busy": "2024-04-24T02:00:55.693292Z",
     "iopub.status.idle": "2024-04-24T02:01:23.715538Z",
     "shell.execute_reply": "2024-04-24T02:01:23.714810Z",
     "shell.execute_reply.started": "2024-04-24T02:00:55.693499Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T10:30:48.703158700Z",
     "start_time": "2024-05-17T10:30:24.050239800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1804874 records\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "# train = pd.read_csv('Data/preprocessed_train.csv')\n",
    "print('loaded %d records' % len(train))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train['comment_text'] = train['comment_text'].astype(str) \n",
    "\n",
    "# List all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "train = convert_dataframe_to_bool(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into 80% train and 20% validate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:01:23.717481Z",
     "iopub.status.busy": "2024-04-24T02:01:23.717163Z",
     "iopub.status.idle": "2024-04-24T02:01:25.493770Z",
     "shell.execute_reply": "2024-04-24T02:01:25.492828Z",
     "shell.execute_reply.started": "2024-04-24T02:01:23.717421Z"
    },
    "trusted": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-17T10:31:09.879775900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, validate_df = model_selection.train_test_split(train, test_size=0.2)\n",
    "print('%d train comments, %d validate comments' % (len(train_df), len(validate_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a text tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:01:25.495531Z",
     "iopub.status.busy": "2024-04-24T02:01:25.495199Z",
     "iopub.status.idle": "2024-04-24T02:03:01.848534Z",
     "shell.execute_reply": "2024-04-24T02:03:01.847824Z",
     "shell.execute_reply.started": "2024-04-24T02:01:25.495454Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:50:53.246151500Z",
     "start_time": "2024-05-17T07:49:08.475486800Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 10000\n",
    "TOXICITY_COLUMN = 'target'\n",
    "TEXT_COLUMN = 'comment_text'\n",
    "\n",
    "# Create a text tokenizer.\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_df[TEXT_COLUMN])\n",
    "\n",
    "# All comments must be truncated or padded to be the same length.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "def pad_text(texts, tokenizer):\n",
    "    return pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train a Convolutional Neural Net for classifying toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:03:01.850248Z",
     "iopub.status.busy": "2024-04-24T02:03:01.850018Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:38:59.836694400Z",
     "start_time": "2024-05-17T09:07:55.386443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model loaded.\n",
      "Loading tokenizer...\n",
      "Tokenizer loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|██████████| 1443899/1443899 [25:53<00:00, 929.39it/s] \n",
      "Encoding texts: 100%|██████████| 360975/360975 [05:07<00:00, 1173.34it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=keras_tensor_14>\n  • attention_mask=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=keras_tensor_15>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 79\u001B[0m\n\u001B[0;32m     69\u001B[0m     model\u001B[38;5;241m.\u001B[39mfit([train_encodings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m], train_encodings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]],\n\u001B[0;32m     70\u001B[0m               train_labels,\n\u001B[0;32m     71\u001B[0m               batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     74\u001B[0m               verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,  \u001B[38;5;66;03m# Set verbose to 0 to not duplicate progress bar\u001B[39;00m\n\u001B[0;32m     75\u001B[0m               callbacks\u001B[38;5;241m=\u001B[39m[tqdm_callback])  \u001B[38;5;66;03m# Add tqdm_callback to callbacks\u001B[39;00m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m---> 79\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_df\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 49\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(train_df, validate_df)\u001B[0m\n\u001B[0;32m     46\u001B[0m attention_mask_input \u001B[38;5;241m=\u001B[39m Input(shape\u001B[38;5;241m=\u001B[39m(MAX_SEQUENCE_LENGTH,), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# BERT Layers\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m bert_output \u001B[38;5;241m=\u001B[39m \u001B[43mbert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask_input\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# We use the pooled output here\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Dropout Layers\u001B[39;00m\n\u001B[0;32m     52\u001B[0m x \u001B[38;5;241m=\u001B[39m Dropout(DROPOUT_RATE)(bert_output)\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:436\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    434\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m--> 436\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m \u001B[43minput_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args_and_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:513\u001B[0m, in \u001B[0;36minput_processing\u001B[1;34m(func, config, **kwargs)\u001B[0m\n\u001B[0;32m    511\u001B[0m         output[k] \u001B[38;5;241m=\u001B[39m v\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 513\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(v)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not allowed only \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mallowed_types\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is accepted for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(main_input, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, \u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(main_input):\n\u001B[0;32m    517\u001B[0m         \u001B[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=keras_tensor_14>\n  • attention_mask=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=keras_tensor_15>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "EMBEDDINGS_PATH = 'Embedding_file/glove.6B.100d.txt'\n",
    "EMBEDDINGS_DIMENSION = 100\n",
    "DROPOUT_RATE = 0.3\n",
    "LEARNING_RATE = 0.00005\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "print(\"Loading BERT model...\")\n",
    "bert_model = TFBertModel.from_pretrained('Models/bert-base-uncased')\n",
    "print(\"BERT model loaded.\")\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('Models/bert-base-uncased')\n",
    "print(\"Tokenizer loaded.\")\n",
    "\n",
    "def encode_texts(texts):\n",
    "    encoded_texts = []\n",
    "    for text in tqdm(texts.tolist(), desc=\"Encoding texts\"):\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_SEQUENCE_LENGTH,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        encoded_texts.append(encoded_text)\n",
    "    return encoded_texts\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    # Prepare data\n",
    "    train_encodings = encode_texts(train_df[TEXT_COLUMN])\n",
    "    train_labels = to_categorical(train_df[TOXICITY_COLUMN])\n",
    "    validate_encodings = encode_texts(validate_df[TEXT_COLUMN])\n",
    "    validate_labels = to_categorical(validate_df[TOXICITY_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Create model layers.\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='sequence_input')\n",
    "    attention_mask_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='attention_mask_input')\n",
    "\n",
    "    # BERT Layers\n",
    "    bert_output = bert_model(sequence_input, attention_mask=attention_mask_input).pooler_output\n",
    "\n",
    "    # Dropout Layers\n",
    "    x = Dropout(DROPOUT_RATE)(bert_output)\n",
    "\n",
    "    # Dense Layers\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Predict Layers\n",
    "    preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Compile model.\n",
    "    model = Model(inputs=[sequence_input, attention_mask_input], outputs=preds)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=LEARNING_RATE),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    # Train model with TQDMCallback.\n",
    "    tqdm_callback = TqdmCallback(verbose=2)  # verbose=2 for less verbosity\n",
    "\n",
    "    model.fit([train_encodings['input_ids'], train_encodings['attention_mask']],\n",
    "              train_labels,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              validation_data=([validate_encodings['input_ids'], validate_encodings['attention_mask']], validate_labels),\n",
    "              verbose=0,  # Set verbose to 0 to not duplicate progress bar\n",
    "              callbacks=[tqdm_callback])  # Add tqdm_callback to callbacks\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:49:53.269991400Z",
     "start_time": "2024-05-17T09:49:53.253055400Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=sequence_input>\n  • attention_mask=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=attention_mask_input>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[17], line 7\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m attention_mask_input \u001B[38;5;241m=\u001B[39m Input(shape\u001B[38;5;241m=\u001B[39m(MAX_SEQUENCE_LENGTH,), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask_input\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# BERT Layers\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m bert_output \u001B[38;5;241m=\u001B[39m \u001B[43mbert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask_input\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpooler_output\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Dropout Layers\u001B[39;00m\n\u001B[0;32m     10\u001B[0m x \u001B[38;5;241m=\u001B[39m Dropout(DROPOUT_RATE)(bert_output)\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:436\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    434\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m--> 436\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m \u001B[43minput_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args_and_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32m~\\Desktop\\CS\\CS340ComputationalEthics\\Project\\Depth2Fairness\\.venv\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:513\u001B[0m, in \u001B[0;36minput_processing\u001B[1;34m(func, config, **kwargs)\u001B[0m\n\u001B[0;32m    511\u001B[0m         output[k] \u001B[38;5;241m=\u001B[39m v\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 513\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(v)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not allowed only \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mallowed_types\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is accepted for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(main_input, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, \u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(main_input):\n\u001B[0;32m    517\u001B[0m         \u001B[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=sequence_input>\n  • attention_mask=<KerasTensor shape=(None, 250), dtype=int32, sparse=None, name=attention_mask_input>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = train_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:49:55.594327300Z",
     "start_time": "2024-05-17T09:49:55.486507900Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate model predictions on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:38:01.053864Z",
     "start_time": "2024-05-17T07:35:40.946260800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22561/22561\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m118s\u001B[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'Bert_model'\n",
    "# save the model\n",
    "model.save('Models/Bert.h5')\n",
    "validate_df[MODEL_NAME] = model.predict(pad_text(validate_df[TEXT_COLUMN], tokenizer))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:40:33.475914800Z",
     "start_time": "2024-05-17T07:40:33.374594600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                id  target                                       comment_text  \\\n2400071        NaN   False  question wisdom ready change system soon good ...   \n660555   1050181.0   False  want weiner investigation go discover informat...   \n554174    921208.0   False  killer moroccan origin report show  publish ja...   \n410934    745991.0   False  shameless bravado juvenile posturing lefty exp...   \n489957    844575.0   False  repub plan  plan  donald j. trump new presiden...   \n\n         severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n2400071              NaN      NaN              NaN       NaN     NaN  False   \n660555               0.0      0.0              0.0  0.000000     0.0  False   \n554174               0.0      0.1              0.3  0.000000     0.3  False   \n410934               0.0      0.0              0.0  0.166667     0.0  False   \n489957               0.0      0.0              0.0  0.000000     0.0  False   \n\n         atheist  ...    rating  funny  wow  sad  likes  disagree  \\\n2400071    False  ...       NaN    NaN  NaN  NaN    NaN       NaN   \n660555     False  ...  approved    0.0  0.0  0.0    2.0       0.0   \n554174     False  ...  approved    0.0  0.0  0.0    0.0       0.0   \n410934     False  ...  rejected    1.0  0.0  0.0    0.0       1.0   \n489957     False  ...  approved    0.0  0.0  0.0    0.0       0.0   \n\n         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \\\n2400071              NaN                       NaN                       NaN   \n660555               0.0                       0.0                       4.0   \n554174               0.0                       6.0                      10.0   \n410934               0.0                       0.0                       6.0   \n489957               0.0                       0.0                       4.0   \n\n         my_model  \n2400071  0.000124  \n660555   0.003940  \n554174   0.099911  \n410934   0.093263  \n489957   0.001096  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>comment_text</th>\n      <th>severe_toxicity</th>\n      <th>obscene</th>\n      <th>identity_attack</th>\n      <th>insult</th>\n      <th>threat</th>\n      <th>asian</th>\n      <th>atheist</th>\n      <th>...</th>\n      <th>rating</th>\n      <th>funny</th>\n      <th>wow</th>\n      <th>sad</th>\n      <th>likes</th>\n      <th>disagree</th>\n      <th>sexual_explicit</th>\n      <th>identity_annotator_count</th>\n      <th>toxicity_annotator_count</th>\n      <th>my_model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2400071</th>\n      <td>NaN</td>\n      <td>False</td>\n      <td>question wisdom ready change system soon good ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000124</td>\n    </tr>\n    <tr>\n      <th>660555</th>\n      <td>1050181.0</td>\n      <td>False</td>\n      <td>want weiner investigation go discover informat...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>approved</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.003940</td>\n    </tr>\n    <tr>\n      <th>554174</th>\n      <td>921208.0</td>\n      <td>False</td>\n      <td>killer moroccan origin report show  publish ja...</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>0.000000</td>\n      <td>0.3</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>approved</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>10.0</td>\n      <td>0.099911</td>\n    </tr>\n    <tr>\n      <th>410934</th>\n      <td>745991.0</td>\n      <td>False</td>\n      <td>shameless bravado juvenile posturing lefty exp...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>rejected</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.093263</td>\n    </tr>\n    <tr>\n      <th>489957</th>\n      <td>844575.0</td>\n      <td>False</td>\n      <td>repub plan  plan  donald j. trump new presiden...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>approved</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.001096</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define bias metrics, then evaluate our new model for bias using the validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:40:44.928180800Z",
     "start_time": "2024-05-17T07:40:39.530826500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n2      homosexual_gay_or_lesbian           2191      0.779656  0.751227   \n6                          black           2969      0.779857  0.712884   \n7                          white           4964      0.786009  0.720060   \n5                         muslim           4253      0.801811  0.776812   \n4                         jewish           1541      0.842341  0.852811   \n8  psychiatric_or_mental_illness            975      0.842646  0.835229   \n1                         female          10700      0.867986  0.852470   \n0                           male           8891      0.870325  0.842911   \n3                      christian           8042      0.887223  0.908032   \n\n   bnsp_auc  \n2  0.953948  \n6  0.964288  \n7  0.965577  \n5  0.954333  \n4  0.939993  \n8  0.948722  \n1  0.947230  \n0  0.953353  \n3  0.925454  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subgroup</th>\n      <th>subgroup_size</th>\n      <th>subgroup_auc</th>\n      <th>bpsn_auc</th>\n      <th>bnsp_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>homosexual_gay_or_lesbian</td>\n      <td>2191</td>\n      <td>0.779656</td>\n      <td>0.751227</td>\n      <td>0.953948</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>black</td>\n      <td>2969</td>\n      <td>0.779857</td>\n      <td>0.712884</td>\n      <td>0.964288</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>white</td>\n      <td>4964</td>\n      <td>0.786009</td>\n      <td>0.720060</td>\n      <td>0.965577</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>muslim</td>\n      <td>4253</td>\n      <td>0.801811</td>\n      <td>0.776812</td>\n      <td>0.954333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jewish</td>\n      <td>1541</td>\n      <td>0.842341</td>\n      <td>0.852811</td>\n      <td>0.939993</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>psychiatric_or_mental_illness</td>\n      <td>975</td>\n      <td>0.842646</td>\n      <td>0.835229</td>\n      <td>0.948722</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>10700</td>\n      <td>0.867986</td>\n      <td>0.852470</td>\n      <td>0.947230</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>8891</td>\n      <td>0.870325</td>\n      <td>0.842911</td>\n      <td>0.953353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>christian</td>\n      <td>8042</td>\n      <td>0.887223</td>\n      <td>0.908032</td>\n      <td>0.925454</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = pd.concat([subgroup_negative_examples, non_subgroup_positive_examples])\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = pd.concat([subgroup_positive_examples, non_subgroup_negative_examples])\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {'subgroup': subgroup, 'subgroup_size': len(dataset[dataset[subgroup]]),\n",
    "                  SUBGROUP_AUC: compute_subgroup_auc(dataset, subgroup, label_col, model),\n",
    "                  BPSN_AUC: compute_bpsn_auc(dataset, subgroup, label_col, model),\n",
    "                  BNSP_AUC: compute_bnsp_auc(dataset, subgroup, label_col, model)}\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "bias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "bias_metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:40:50.761083300Z",
     "start_time": "2024-05-17T07:40:50.515163800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.8750458072206464"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n",
    "get_final_metric(bias_metrics_df, calculate_overall_auc(validate_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T08:30:34.347941900Z",
     "start_time": "2024-05-10T08:30:33.636985700Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data/test.csv')\n",
    "submission = pd.read_csv('Data/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T08:33:36.825736400Z",
     "start_time": "2024-05-10T08:32:00.225097600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3042/3042\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "submission['prediction'] = model.predict(pad_text(test[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "submission.to_csv('benchmark_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:28.631939200Z",
     "start_time": "2024-05-10T01:21:28.499695900Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:28.706894800Z",
     "start_time": "2024-05-10T01:21:28.656356300Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:29.082928600Z",
     "start_time": "2024-05-10T01:21:29.026616200Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:29.342147300Z",
     "start_time": "2024-05-10T01:21:29.279707Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:29.470845300Z",
     "start_time": "2024-05-10T01:21:29.443628700Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:29.704400500Z",
     "start_time": "2024-05-10T01:21:29.618457400Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.059866200Z",
     "start_time": "2024-05-10T01:21:30.006733500Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.166317500Z",
     "start_time": "2024-05-10T01:21:30.062808100Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.431124900Z",
     "start_time": "2024-05-10T01:21:30.219983700Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.623142600Z",
     "start_time": "2024-05-10T01:21:30.544704Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.738587700Z",
     "start_time": "2024-05-10T01:21:30.627970400Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:21:30.881373400Z",
     "start_time": "2024-05-10T01:21:30.789628200Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1375107,
     "sourceId": 12500,
     "sourceType": "competition"
    },
    {
     "datasetId": 1835,
     "sourceId": 3176,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 23026,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
